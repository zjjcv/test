{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-seed Grokking Results Visualization\n",
        "\n",
        "This notebook visualizes results from multi-seed grokking experiments.\n",
        "Each plot shows:\n",
        "- Train Accuracy (left y-axis)\n",
        "- Test Accuracy (left y-axis)\n",
        "- A specific metric (right y-axis): Complexity, LLC, L2 Norm, or Spectral Entropy\n",
        "\n",
        "All plots show mean ± std over multiple seeds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Generating plots: 9 tasks × 2 WDs × 6 metrics\n",
            "Total: 108 figures\n",
            "======================================================================\n",
            "\n",
            "✓ x+y             WD=0.0 → 6 plots generated\n",
            "✓ x+y             WD=1.0 → 6 plots generated\n",
            "✓ x-y             WD=0.0 → 6 plots generated\n",
            "✓ x-y             WD=1.0 → 6 plots generated\n",
            "✓ x*y             WD=0.0 → 6 plots generated\n",
            "✓ x*y             WD=1.0 → 6 plots generated\n",
            "✓ x_div_y         WD=0.0 → 6 plots generated\n",
            "✓ x_div_y         WD=1.0 → 6 plots generated\n",
            "✓ x2+y2           WD=0.0 → 6 plots generated\n",
            "✓ x2+y2           WD=1.0 → 6 plots generated\n",
            "✓ x2+xy+y2        WD=0.0 → 6 plots generated\n",
            "✓ x2+xy+y2        WD=1.0 → 6 plots generated\n",
            "✓ x2+xy+y2+x      WD=0.0 → 6 plots generated\n",
            "✓ x2+xy+y2+x      WD=1.0 → 6 plots generated\n",
            "✓ x3+xy           WD=0.0 → 6 plots generated\n",
            "✓ x3+xy           WD=1.0 → 6 plots generated\n",
            "✓ x3+xy2+y        WD=0.0 → 6 plots generated\n",
            "✓ x3+xy2+y        WD=1.0 → 6 plots generated\n",
            "\n",
            "======================================================================\n",
            "All plots saved to: /root/autodl-tmp/test/results/plots\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "def plot_with_metric(task_name, wd, results_base=\"/root/autodl-tmp/test/results/data\", save_dir=None):\n",
        "    \"\"\"绘制训练/测试acc + 各个单独指标的图\"\"\"\n",
        "    task_safe = task_name.replace(\"/\", \"_div_\").replace(\"*\", \"_mul_\").replace(\"+\", \"_plus_\")\n",
        "    data_dir = Path(results_base) / task_safe / f\"wd_{wd}\"\n",
        "    seed_files = sorted(list(data_dir.glob(\"seed*.csv\")))\n",
        "    \n",
        "    if not seed_files:\n",
        "        print(f\"⚠ No data: {task_name} WD={wd}\")\n",
        "        return\n",
        "    \n",
        "    # 加载数据\n",
        "    all_data = []\n",
        "    for seed_file in seed_files:\n",
        "        data = {}\n",
        "        with open(seed_file, 'r') as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for row in reader:\n",
        "                for key, value in row.items():\n",
        "                    if key not in data: data[key] = []\n",
        "                    data[key].append(float(value))\n",
        "        all_data.append(data)\n",
        "    \n",
        "    # 计算统计量\n",
        "    steps = np.array(all_data[0]['steps'])\n",
        "    def stats(key):\n",
        "        d = np.array([x[key] for x in all_data])\n",
        "        return np.mean(d, axis=0), np.std(d, axis=0)\n",
        "    \n",
        "    train_acc_m, train_acc_s = stats('train_acc')\n",
        "    test_acc_m, test_acc_s = stats('test_acc')\n",
        "    llc_m, llc_s = stats('llc')\n",
        "    l2_m, l2_s = stats('l2_norm')\n",
        "    se_m, se_s = stats('spectral_entropy')\n",
        "    attn_se_m, attn_se_s = stats('attention_spectral_entropy')\n",
        "    emb_se_m, emb_se_s = stats('embedding_spectral_entropy')\n",
        "    complexity_m = llc_m * l2_m\n",
        "    complexity_s = np.sqrt((llc_s * l2_m)**2 + (llc_m * l2_s)**2)\n",
        "    \n",
        "    # 定义要绘制的指标\n",
        "    metrics = [\n",
        "        ('Complexity (LLC×L2)', complexity_m, complexity_s, 'green'),\n",
        "        ('LLC', llc_m, llc_s, 'purple'),\n",
        "        ('L2 Norm', l2_m, l2_s, 'orange'),\n",
        "        ('Spectral Entropy', se_m, se_s, 'brown'),\n",
        "        ('Attention Entropy', attn_se_m, attn_se_s, 'cyan'),\n",
        "        ('Embedding Entropy', emb_se_m, emb_se_s, 'magenta'),\n",
        "    ]\n",
        "    \n",
        "    # 为每个指标生成一张图\n",
        "    for metric_name, metric_m, metric_s, color in metrics:\n",
        "        fig, ax1 = plt.subplots(figsize=(12, 7))\n",
        "        ax2 = ax1.twinx()\n",
        "        \n",
        "        # 左轴：训练和测试准确率\n",
        "        line1 = ax1.plot(steps, train_acc_m, 'b-', label='Train Acc', linewidth=2, alpha=0.8)\n",
        "        ax1.fill_between(steps, train_acc_m - train_acc_s, train_acc_m + train_acc_s, \n",
        "                         color='blue', alpha=0.15)\n",
        "        line2 = ax1.plot(steps, test_acc_m, 'r-', label='Test Acc', linewidth=2.5, alpha=0.9)\n",
        "        ax1.fill_between(steps, test_acc_m - test_acc_s, test_acc_m + test_acc_s, \n",
        "                         color='red', alpha=0.2)\n",
        "        \n",
        "        ax1.set_xlabel('Training Steps', fontsize=13, fontweight='bold')\n",
        "        ax1.set_ylabel('Accuracy', fontsize=13, fontweight='bold', color='black')\n",
        "        ax1.tick_params(axis='y', labelcolor='black')\n",
        "        ax1.set_xscale('log')\n",
        "        ax1.set_ylim(-0.05, 1.05)\n",
        "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "        \n",
        "        # 右轴：特定指标\n",
        "        line3 = ax2.plot(steps, metric_m, color=color, linestyle='--', \n",
        "                        label=metric_name, linewidth=2.5, alpha=0.9)\n",
        "        ax2.fill_between(steps, metric_m - metric_s, metric_m + metric_s, \n",
        "                         color=color, alpha=0.2)\n",
        "        \n",
        "        ax2.set_ylabel(metric_name, fontsize=13, fontweight='bold', color=color)\n",
        "        ax2.tick_params(axis='y', labelcolor=color)\n",
        "        \n",
        "        # 合并图例\n",
        "        lines = line1 + line2 + line3\n",
        "        labels = [l.get_label() for l in lines]\n",
        "        ax1.legend(lines, labels, loc='best', fontsize=11, framealpha=0.95)\n",
        "        \n",
        "        # 标题\n",
        "        plt.title(f'Task: {task_name} | WD={wd} | {metric_name}\\n(Mean ± Std, {len(all_data)} seeds)', \n",
        "                 fontsize=14, fontweight='bold', pad=15)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save_dir:\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            metric_safe = metric_name.replace(' ', '_').replace('(', '').replace(')', '').replace('×', 'x')\n",
        "            save_path = os.path.join(save_dir, f\"{task_safe}_wd{wd}_{metric_safe}.png\")\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        \n",
        "        plt.close()\n",
        "    \n",
        "    print(f\"✓ {task_name:15s} WD={wd} → 6 plots generated\")\n",
        "\n",
        "# 批量绘制所有任务（9个任务 × 2个权重衰减 × 6个指标 = 108张图）\n",
        "tasks = ['x+y', 'x-y', 'x*y', 'x_div_y', 'x2+y2', 'x2+xy+y2', 'x2+xy+y2+x', 'x3+xy', 'x3+xy2+y']\n",
        "weight_decays = [0.0, 1.0]\n",
        "save_base = '/root/autodl-tmp/test/results/plots'\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Generating plots: {len(tasks)} tasks × {len(weight_decays)} WDs × 6 metrics\")\n",
        "print(f\"Total: {len(tasks) * len(weight_decays) * 6} figures\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "for task in tasks:\n",
        "    for wd in weight_decays:\n",
        "        try:\n",
        "            plot_with_metric(task, wd, save_dir=save_base)\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error in {task} WD={wd}: {e}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"All plots saved to: {save_base}\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Processing: 9 tasks × 2 WDs (3 seeds combined)\n",
            "======================================================================\n",
            "\n",
            "✓ x+y             WD=0.0\n",
            "✓ x+y             WD=1.0\n",
            "✓ x-y             WD=0.0\n",
            "✓ x-y             WD=1.0\n",
            "✓ x*y             WD=0.0\n",
            "✓ x*y             WD=1.0\n",
            "✓ x_div_y         WD=0.0\n",
            "✓ x_div_y         WD=1.0\n",
            "✓ x2+y2           WD=0.0\n",
            "✓ x2+y2           WD=1.0\n",
            "✓ x2+xy+y2        WD=0.0\n",
            "✓ x2+xy+y2        WD=1.0\n",
            "✓ x2+xy+y2+x      WD=0.0\n",
            "✓ x2+xy+y2+x      WD=1.0\n",
            "✓ x3+xy           WD=0.0\n",
            "✓ x3+xy           WD=1.0\n",
            "✓ x3+xy2+y        WD=0.0\n",
            "✓ x3+xy2+y        WD=1.0\n",
            "\n",
            "======================================================================\n",
            "Done! Saved to: /root/autodl-tmp/test/results/embedding_viz\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import torch\n",
        "\n",
        "tasks = ['x+y', 'x-y', 'x*y', 'x_div_y', 'x2+y2', 'x2+xy+y2', 'x2+xy+y2+x', 'x3+xy', 'x3+xy2+y']\n",
        "weight_decays = [0.0, 1.0]\n",
        "seeds = [42, 101, 2025]\n",
        "steps = [100, 1000, 10000, 100000]\n",
        "seed_colors = {42: 'red', 101: 'blue', 2025: 'green'}\n",
        "seed_markers = {42: 'o', 101: 's', 2025: '^'}\n",
        "checkpoint_base = Path(\"/root/autodl-tmp/test/results/checkpoints\")\n",
        "save_base = Path(\"/root/autodl-tmp/test/results/embedding_viz\")\n",
        "save_base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Processing: {len(tasks)} tasks × {len(weight_decays)} WDs (3 seeds combined)\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "for task in tasks:\n",
        "    task_safe = task.replace(\"/\", \"_div_\").replace(\"*\", \"_mul_\").replace(\"+\", \"_plus_\")\n",
        "    for wd in weight_decays:\n",
        "        checkpoint_dir = checkpoint_base / task_safe / f\"wd_{wd}\"\n",
        "        if not checkpoint_dir.exists():\n",
        "            continue\n",
        "        \n",
        "        fig, axes = plt.subplots(4, 4, figsize=(24, 24))\n",
        "        found_any = False\n",
        "        \n",
        "        for step_idx, step in enumerate(steps):\n",
        "            # 收集所有种子的embedding\n",
        "            all_input_embs, all_output_embs = [], []\n",
        "            seed_labels = []\n",
        "            vocab_size = None\n",
        "            \n",
        "            for seed in seeds:\n",
        "                checkpoint_file = checkpoint_dir / f\"seed{seed}_step{step}.pt\"\n",
        "                if not checkpoint_file.exists():\n",
        "                    continue\n",
        "                \n",
        "                checkpoint = torch.load(checkpoint_file, map_location='cpu', weights_only=False)\n",
        "                state_dict = checkpoint['model_state_dict']\n",
        "                input_emb = state_dict['token_embeddings.weight'].numpy()\n",
        "                output_emb = state_dict['head.weight'].numpy()\n",
        "                \n",
        "                all_input_embs.append(input_emb)\n",
        "                all_output_embs.append(output_emb)\n",
        "                seed_labels.extend([seed] * input_emb.shape[0])\n",
        "                if vocab_size is None:\n",
        "                    vocab_size = input_emb.shape[0]\n",
        "            \n",
        "            if not all_input_embs:\n",
        "                continue\n",
        "            \n",
        "            found_any = True\n",
        "            combined_input = np.vstack(all_input_embs)\n",
        "            combined_output = np.vstack(all_output_embs)\n",
        "            \n",
        "            # Input PCA\n",
        "            pca = PCA(n_components=2)\n",
        "            input_pca = pca.fit_transform(combined_input)\n",
        "            ax = axes[step_idx, 0]\n",
        "            for seed in seeds:\n",
        "                mask = np.array(seed_labels) == seed\n",
        "                ax.scatter(input_pca[mask, 0], input_pca[mask, 1], \n",
        "                          c=seed_colors[seed], marker=seed_markers[seed], \n",
        "                          s=60, alpha=0.6, label=f'Seed {seed}')\n",
        "            # 标注数字（使用第一个种子的位置）\n",
        "            for i in range(min(vocab_size, 15)):\n",
        "                ax.annotate(str(i), (input_pca[i, 0], input_pca[i, 1]), \n",
        "                           fontsize=7, alpha=0.7, fontweight='bold')\n",
        "            ax.set_title(f'Input PCA (Step {step})', fontsize=11, fontweight='bold')\n",
        "            ax.set_xlabel('PC1', fontsize=9)\n",
        "            ax.set_ylabel('PC2', fontsize=9)\n",
        "            ax.legend(fontsize=8, loc='upper right')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Input t-SNE\n",
        "            perplexity = min(30, combined_input.shape[0] - 1)\n",
        "            tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
        "            input_tsne = tsne.fit_transform(combined_input)\n",
        "            ax = axes[step_idx, 1]\n",
        "            for seed in seeds:\n",
        "                mask = np.array(seed_labels) == seed\n",
        "                ax.scatter(input_tsne[mask, 0], input_tsne[mask, 1], \n",
        "                          c=seed_colors[seed], marker=seed_markers[seed], \n",
        "                          s=60, alpha=0.6, label=f'Seed {seed}')\n",
        "            for i in range(min(vocab_size, 15)):\n",
        "                ax.annotate(str(i), (input_tsne[i, 0], input_tsne[i, 1]), \n",
        "                           fontsize=7, alpha=0.7, fontweight='bold')\n",
        "            ax.set_title(f'Input t-SNE (Step {step})', fontsize=11, fontweight='bold')\n",
        "            ax.set_xlabel('t-SNE 1', fontsize=9)\n",
        "            ax.set_ylabel('t-SNE 2', fontsize=9)\n",
        "            ax.legend(fontsize=8, loc='upper right')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Output PCA\n",
        "            pca = PCA(n_components=2)\n",
        "            output_pca = pca.fit_transform(combined_output)\n",
        "            ax = axes[step_idx, 2]\n",
        "            for seed in seeds:\n",
        "                mask = np.array(seed_labels) == seed\n",
        "                ax.scatter(output_pca[mask, 0], output_pca[mask, 1], \n",
        "                          c=seed_colors[seed], marker=seed_markers[seed], \n",
        "                          s=60, alpha=0.6, label=f'Seed {seed}')\n",
        "            for i in range(min(vocab_size, 15)):\n",
        "                ax.annotate(str(i), (output_pca[i, 0], output_pca[i, 1]), \n",
        "                           fontsize=7, alpha=0.7, fontweight='bold')\n",
        "            ax.set_title(f'Output PCA (Step {step})', fontsize=11, fontweight='bold')\n",
        "            ax.set_xlabel('PC1', fontsize=9)\n",
        "            ax.set_ylabel('PC2', fontsize=9)\n",
        "            ax.legend(fontsize=8, loc='upper right')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Output t-SNE\n",
        "            tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
        "            output_tsne = tsne.fit_transform(combined_output)\n",
        "            ax = axes[step_idx, 3]\n",
        "            for seed in seeds:\n",
        "                mask = np.array(seed_labels) == seed\n",
        "                ax.scatter(output_tsne[mask, 0], output_tsne[mask, 1], \n",
        "                          c=seed_colors[seed], marker=seed_markers[seed], \n",
        "                          s=60, alpha=0.6, label=f'Seed {seed}')\n",
        "            for i in range(min(vocab_size, 15)):\n",
        "                ax.annotate(str(i), (output_tsne[i, 0], output_tsne[i, 1]), \n",
        "                           fontsize=7, alpha=0.7, fontweight='bold')\n",
        "            ax.set_title(f'Output t-SNE (Step {step})', fontsize=11, fontweight='bold')\n",
        "            ax.set_xlabel('t-SNE 1', fontsize=9)\n",
        "            ax.set_ylabel('t-SNE 2', fontsize=9)\n",
        "            ax.legend(fontsize=8, loc='upper right')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        if found_any:\n",
        "            plt.suptitle(f'Task: {task} | WD={wd} | Multi-seed Embedding (Seeds: 42, 101, 2025)', \n",
        "                        fontsize=16, fontweight='bold', y=0.995)\n",
        "            plt.tight_layout()\n",
        "            save_path = save_base / f\"{task_safe}_wd{wd}_multiseed_embeddings.png\"\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"✓ {task:15s} WD={wd}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Done! Saved to: {save_base}\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Processing: 9 tasks × 2 WDs (Seed 101 only)\n",
            "======================================================================\n",
            "\n",
            "✓ x+y             WD=0.0\n",
            "✓ x+y             WD=1.0\n",
            "✓ x-y             WD=0.0\n",
            "✓ x-y             WD=1.0\n",
            "✓ x*y             WD=0.0\n",
            "✓ x*y             WD=1.0\n",
            "✓ x_div_y         WD=0.0\n",
            "✓ x_div_y         WD=1.0\n",
            "✓ x2+y2           WD=0.0\n",
            "✓ x2+y2           WD=1.0\n",
            "✓ x2+xy+y2        WD=0.0\n",
            "✓ x2+xy+y2        WD=1.0\n",
            "✓ x2+xy+y2+x      WD=0.0\n",
            "✓ x2+xy+y2+x      WD=1.0\n",
            "✓ x3+xy           WD=0.0\n",
            "✓ x3+xy           WD=1.0\n",
            "✓ x3+xy2+y        WD=0.0\n",
            "✓ x3+xy2+y        WD=1.0\n",
            "\n",
            "======================================================================\n",
            "Done! Saved to: /root/autodl-tmp/test/results/embedding_viz_single\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import torch\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "tasks = ['x+y', 'x-y', 'x*y', 'x_div_y', 'x2+y2', 'x2+xy+y2', 'x2+xy+y2+x', 'x3+xy', 'x3+xy2+y']\n",
        "weight_decays = [0.0, 1.0]\n",
        "seed = 101\n",
        "steps = [100, 1000, 10000, 100000]\n",
        "checkpoint_base = Path(\"/root/autodl-tmp/test/results/checkpoints\")\n",
        "save_base = Path(\"/root/autodl-tmp/test/results/embedding_viz_single\")\n",
        "save_base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Processing: {len(tasks)} tasks × {len(weight_decays)} WDs (Seed {seed} only)\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "for task in tasks:\n",
        "    task_safe = task.replace(\"/\", \"_div_\").replace(\"*\", \"_mul_\").replace(\"+\", \"_plus_\")\n",
        "    for wd in weight_decays:\n",
        "        checkpoint_dir = checkpoint_base / task_safe / f\"wd_{wd}\"\n",
        "        if not checkpoint_dir.exists():\n",
        "            continue\n",
        "        \n",
        "        fig, axes = plt.subplots(4, 4, figsize=(22, 22))\n",
        "        found_any = False\n",
        "        \n",
        "        for step_idx, step in enumerate(steps):\n",
        "            checkpoint_file = checkpoint_dir / f\"seed{seed}_step{step}.pt\"\n",
        "            if not checkpoint_file.exists():\n",
        "                continue\n",
        "            \n",
        "            found_any = True\n",
        "            checkpoint = torch.load(checkpoint_file, map_location='cpu', weights_only=False)\n",
        "            state_dict = checkpoint['model_state_dict']\n",
        "            \n",
        "            input_emb = state_dict['token_embeddings.weight'].numpy()\n",
        "            output_emb = state_dict['head.weight'].numpy()\n",
        "            vocab_size = input_emb.shape[0]\n",
        "            \n",
        "            # Input PCA\n",
        "            pca = PCA(n_components=2)\n",
        "            input_pca = pca.fit_transform(input_emb)\n",
        "            ax = axes[step_idx, 0]\n",
        "            scatter = ax.scatter(input_pca[:, 0], input_pca[:, 1], c=range(vocab_size), \n",
        "                                cmap='viridis', s=100, alpha=0.8, edgecolors='white', linewidths=1)\n",
        "            cbar = plt.colorbar(scatter, ax=ax, fraction=0.046, pad=0.04)\n",
        "            cbar.set_label('Token ID', fontsize=9)\n",
        "            ax.set_title(f'Input Emb PCA (Step {step})', fontsize=12, fontweight='bold')\n",
        "            ax.set_xlabel('PC1', fontsize=10)\n",
        "            ax.set_ylabel('PC2', fontsize=10)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Input t-SNE\n",
        "            tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, vocab_size-1))\n",
        "            input_tsne = tsne.fit_transform(input_emb)\n",
        "            ax = axes[step_idx, 1]\n",
        "            scatter = ax.scatter(input_tsne[:, 0], input_tsne[:, 1], c=range(vocab_size), \n",
        "                                cmap='viridis', s=100, alpha=0.8, edgecolors='white', linewidths=1)\n",
        "            cbar = plt.colorbar(scatter, ax=ax, fraction=0.046, pad=0.04)\n",
        "            cbar.set_label('Token ID', fontsize=9)\n",
        "            ax.set_title(f'Input Emb t-SNE (Step {step})', fontsize=12, fontweight='bold')\n",
        "            ax.set_xlabel('t-SNE 1', fontsize=10)\n",
        "            ax.set_ylabel('t-SNE 2', fontsize=10)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Output PCA\n",
        "            pca = PCA(n_components=2)\n",
        "            output_pca = pca.fit_transform(output_emb)\n",
        "            ax = axes[step_idx, 2]\n",
        "            scatter = ax.scatter(output_pca[:, 0], output_pca[:, 1], c=range(vocab_size), \n",
        "                                cmap='viridis', s=100, alpha=0.8, edgecolors='white', linewidths=1)\n",
        "            cbar = plt.colorbar(scatter, ax=ax, fraction=0.046, pad=0.04)\n",
        "            cbar.set_label('Token ID', fontsize=9)\n",
        "            ax.set_title(f'Output Emb PCA (Step {step})', fontsize=12, fontweight='bold')\n",
        "            ax.set_xlabel('PC1', fontsize=10)\n",
        "            ax.set_ylabel('PC2', fontsize=10)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Output t-SNE\n",
        "            tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, vocab_size-1))\n",
        "            output_tsne = tsne.fit_transform(output_emb)\n",
        "            ax = axes[step_idx, 3]\n",
        "            scatter = ax.scatter(output_tsne[:, 0], output_tsne[:, 1], c=range(vocab_size), \n",
        "                                cmap='viridis', s=100, alpha=0.8, edgecolors='white', linewidths=1)\n",
        "            cbar = plt.colorbar(scatter, ax=ax, fraction=0.046, pad=0.04)\n",
        "            cbar.set_label('Token ID', fontsize=9)\n",
        "            ax.set_title(f'Output Emb t-SNE (Step {step})', fontsize=12, fontweight='bold')\n",
        "            ax.set_xlabel('t-SNE 1', fontsize=10)\n",
        "            ax.set_ylabel('t-SNE 2', fontsize=10)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        if found_any:\n",
        "            plt.suptitle(f'Task: {task} | WD={wd} | Seed={seed}', \n",
        "                        fontsize=18, fontweight='bold', y=0.995)\n",
        "            plt.tight_layout()\n",
        "            save_path = save_base / f\"{task_safe}_wd{wd}_seed{seed}_embeddings.png\"\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"✓ {task:15s} WD={wd}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Done! Saved to: {save_base}\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 定义能够输出注意力权重的模型\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, num_heads, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(dim, num_heads, batch_first=True, dropout=dropout)\n",
        "        self.ln_2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, dim * 4), nn.GELU(), nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x, attn_mask=None, return_attn=False):\n",
        "        ln_x = self.ln_1(x)\n",
        "        if return_attn:\n",
        "            attn_out, attn_weights = self.attn(ln_x, ln_x, ln_x, attn_mask=attn_mask, need_weights=True, average_attn_weights=False)\n",
        "            x = x + attn_out\n",
        "            x = x + self.mlp(self.ln_2(x))\n",
        "            return x, attn_weights\n",
        "        else:\n",
        "            x = x + self.attn(ln_x, ln_x, ln_x, attn_mask=attn_mask, need_weights=False)[0]\n",
        "            x = x + self.mlp(self.ln_2(x))\n",
        "            return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dim=128, num_layers=2, num_heads=4, num_tokens=97, seq_len=5, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = nn.Embedding(num_tokens, dim)\n",
        "        self.position_embeddings = nn.Embedding(seq_len, dim)\n",
        "        self.layers = nn.ModuleList([Block(dim, num_heads, dropout) for _ in range(num_layers)])\n",
        "        self.ln_f = nn.LayerNorm(dim)\n",
        "        self.head = nn.Linear(dim, num_tokens, bias=False)\n",
        "        mask = torch.triu(torch.full((seq_len, seq_len), float('-inf')), diagonal=1)\n",
        "        self.register_buffer(\"causal_mask\", mask)\n",
        "        self.register_buffer(\"pos_ids\", torch.arange(seq_len))\n",
        "    \n",
        "    def forward(self, x, return_attn=False):\n",
        "        h = self.token_embeddings(x) + self.position_embeddings(self.pos_ids[:x.size(1)])\n",
        "        mask = self.causal_mask[:x.size(1), :x.size(1)]\n",
        "        \n",
        "        if return_attn:\n",
        "            attn_weights_list = []\n",
        "            for layer in self.layers:\n",
        "                h, attn_weights = layer(h, attn_mask=mask, return_attn=True)\n",
        "                attn_weights_list.append(attn_weights)\n",
        "            logits = self.head(self.ln_f(h))\n",
        "            return logits, attn_weights_list\n",
        "        else:\n",
        "            for layer in self.layers:\n",
        "                h = layer(h, attn_mask=mask)\n",
        "            return self.head(self.ln_f(h))\n",
        "\n",
        "# 可视化注意力热力图\n",
        "task = 'x-y'\n",
        "wd = 1.0\n",
        "seed = 101\n",
        "steps = [100, 1000, 10000, 100000]\n",
        "task_safe = task.replace(\"/\", \"_div_\").replace(\"*\", \"_mul_\").replace(\"+\", \"_plus_\")\n",
        "checkpoint_base = Path(\"/root/autodl-tmp/test/results/checkpoints\")\n",
        "checkpoint_dir = checkpoint_base / task_safe / f\"wd_{wd}\"\n",
        "save_base = Path(\"/root/autodl-tmp/test/results/attention_viz\")\n",
        "save_base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 创建测试输入：例如 50 - 30 = 20 (mod 97)\n",
        "# 格式: [x, op, y, eq]，期望输出result\n",
        "p = 97\n",
        "x, y = 50, 30\n",
        "op_token = p  # x-y的操作符\n",
        "eq_token = p  # 等号\n",
        "result = (x - y) % p\n",
        "test_input = torch.tensor([[x, op_token, y, eq_token]]).long()\n",
        "\n",
        "print(f\"Test input: {x} - {y} = {result} (mod {p})\")\n",
        "print(f\"Input tokens: {test_input.tolist()}\")\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Visualizing attention for task: {task} | WD={wd} | Seed={seed}\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# 为每个训练步数生成可视化\n",
        "fig, axes = plt.subplots(len(steps), 2, figsize=(16, 4 * len(steps)))\n",
        "\n",
        "for step_idx, step in enumerate(steps):\n",
        "    checkpoint_file = checkpoint_dir / f\"seed{seed}_step{step}.pt\"\n",
        "    if not checkpoint_file.exists():\n",
        "        print(f\"⚠ Missing: {checkpoint_file}\")\n",
        "        continue\n",
        "    \n",
        "    # 加载模型\n",
        "    checkpoint = torch.load(checkpoint_file, map_location='cpu', weights_only=False)\n",
        "    model = Decoder(dim=128, num_layers=2, num_heads=4, num_tokens=p+2, seq_len=5)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "    model.eval()\n",
        "    \n",
        "    # 前向传播并获取注意力权重\n",
        "    with torch.no_grad():\n",
        "        logits, attn_weights_list = model(test_input, return_attn=True)\n",
        "        prediction = logits[0, -1].argmax().item()\n",
        "        confidence = torch.softmax(logits[0, -1], dim=0).max().item()\n",
        "    \n",
        "    # 绘制每一层的注意力热力图\n",
        "    for layer_idx, attn_weights in enumerate(attn_weights_list):\n",
        "        # attn_weights shape: [batch, num_heads, seq_len, seq_len]\n",
        "        # 对所有head取平均\n",
        "        avg_attn = attn_weights[0].mean(dim=0).numpy()  # [seq_len, seq_len]\n",
        "        \n",
        "        ax = axes[step_idx, layer_idx]\n",
        "        sns.heatmap(avg_attn, annot=True, fmt='.3f', cmap='viridis', \n",
        "                   cbar_kws={'label': 'Attention Weight'}, \n",
        "                   xticklabels=[f'{x}', 'op', f'{y}', 'eq'],\n",
        "                   yticklabels=[f'{x}', 'op', f'{y}', 'eq'],\n",
        "                   vmin=0, vmax=1, ax=ax, square=True)\n",
        "        \n",
        "        # 标题显示预测结果\n",
        "        acc_status = \"✓\" if prediction == result else \"✗\"\n",
        "        ax.set_title(f'Step {step} | Layer {layer_idx+1} | Pred: {prediction} {acc_status} (Conf: {confidence:.3f})', \n",
        "                    fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel('Key Position', fontsize=10)\n",
        "        ax.set_ylabel('Query Position', fontsize=10)\n",
        "    \n",
        "    print(f\"✓ Step {step:6d}: Pred={prediction:2d} (True={result:2d}) | Confidence={confidence:.3f} | {'Correct' if prediction==result else 'Wrong'}\")\n",
        "\n",
        "plt.suptitle(f'Attention Patterns | Task: {task} | WD={wd} | Seed={seed}\\nInput: {x} - {y} = {result}', \n",
        "            fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = save_base / f\"{task_safe}_wd{wd}_seed{seed}_attention.png\"\n",
        "plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Saved to: {save_path}\")\n",
        "print(f\"{'='*70}\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
